{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://mccormickml.com/2019/05/14/BERT-word-embeddings-tutorial/#1-loading-pre-trained-bert\n",
    "import torch\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "tokenizer = BertTokenizer.from_pretrained('bert/en/uncased_L-12_H-768_A-12')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['here', 'is', 'the', 'sentence', 'i', 'want', 'em', '##bed', '##ding', '##s', 'for', '.']\n"
     ]
    }
   ],
   "source": [
    "text = \"Here is the sentence I want embeddings for.\"\n",
    "# makerd_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "makerd_text = text \n",
    "tokenized_text = tokenizer.tokenize(makerd_text)\n",
    "print(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30522"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.vocab.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[             1,031\n",
      "cl           18,856\n",
      "##s           2,015\n",
      "]             1,033\n",
      "after         2,044\n",
      "stealing     11,065\n",
      "money         2,769\n",
      "from          2,013\n",
      "the           1,996\n",
      "bank          2,924\n",
      "vault        11,632\n",
      ",             1,010\n",
      "the           1,996\n",
      "bank          2,924\n",
      "robber       27,307\n",
      "was           2,001\n",
      "seen          2,464\n",
      "fishing       5,645\n",
      "on            2,006\n",
      "the           1,996\n",
      "mississippi   5,900\n",
      "river         2,314\n",
      "bank          2,924\n",
      ".             1,012\n",
      "[             1,031\n",
      "sep          19,802\n",
      "]             1,033\n"
     ]
    }
   ],
   "source": [
    "text = \"After stealing money from the bank vault, the bank robber was  seen \" \\\n",
    "       \"fishing on the Mississippi river bank.\"\n",
    "marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "tokenized_text = tokenizer.tokenize(marked_text)\n",
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "\n",
    "for tup in zip(tokenized_text, indexed_tokens):\n",
    "    print('{:<12} {:>6,}'.format(tup[0], tup[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mType:\u001b[0m        BertTokenizer\n",
       "\u001b[0;31mString form:\u001b[0m <pytorch_pretrained_bert.tokenization.BertTokenizer object at 0x121b8d630>\n",
       "\u001b[0;31mFile:\u001b[0m        ~/.pyenv/versions/3.6.5/envs/bert_client_api/lib/python3.6/site-packages/pytorch_pretrained_bert/tokenization.py\n",
       "\u001b[0;31mDocstring:\u001b[0m   Runs end-to-end tokenization: punctuation splitting + wordpiece\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
