{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] 山田さんが 顔 を見たのはこれが初めてでした 。 巨大だった 。 [SEP]\n",
      "[CLS] 山田さんが 面倒 を見たのはこれが初めてでした 。 巨大だった 。 [SEP]\n",
      "[CLS] 山田さんが 目 を見たのはこれが初めてでした 。 巨大だった 。 [SEP]\n",
      "[CLS] 山田さんが 夢 を見たのはこれが初めてでした 。 巨大だった 。 [SEP]\n",
      "[CLS] 山田さんが 姿 を見たのはこれが初めてでした 。 巨大だった 。 [SEP]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers.modeling_bert import BertForMaskedLM\n",
    "from transformers.tokenization_bert_japanese import BertJapaneseTokenizer\n",
    "\n",
    "tokenizer = BertJapaneseTokenizer.from_pretrained(\"bert/ja/BERT-base_mecab-ipadic-bpe-32k_whole-word-mask\")\n",
    "model = BertForMaskedLM.from_pretrained(\"bert/ja/BERT-base_mecab-ipadic-bpe-32k_whole-word-mask\")\n",
    "model.eval()\n",
    "\n",
    "input_ids = tokenizer.encode(f\"\"\"\n",
    "山田さんが{tokenizer.mask_token}を見たのはこれが初めてでした。巨大だった。\n",
    "\"\"\", return_tensors=\"pt\")\n",
    "\n",
    "masked_index = torch.where(input_ids == tokenizer.mask_token_id)[1].tolist()[0]\n",
    "\n",
    "result = model(input_ids)\n",
    "result = result[0][:, masked_index].topk(5).indices.tolist()[0]\n",
    "\n",
    "for r in result:\n",
    "    output = input_ids[0].tolist()\n",
    "    output[masked_index] = r\n",
    "    print(tokenizer.decode(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 23])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 240])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "日曜日の16時頃に訪問。\n",
    "お店の前は通った事がありましたが\n",
    "今回やっと初訪問。\n",
    "\n",
    "この日はセールをやっていたようで\n",
    "いつも外から眺めている印象よりお客さんが多いですね。\n",
    "\n",
    "様々な種類のお肉が売っておりましたが\n",
    "既に加工していたり揚げていたりする商品もあったので\n",
    "そちらを中心に物色します。\n",
    "\n",
    "コロッケやメンチカツなどもありましたが\n",
    "唐揚げと串揚げを購入。\n",
    "\n",
    "唐揚げはグラム数で計り売りで2個で95円でした。\n",
    "串揚げは150円でした。\n",
    "\n",
    "その日の夜に特に温めずに頂きましたが\n",
    "唐揚げは温めなくてもジューシーな味わいで\n",
    "個人的には非常に好みの味。\n",
    "\n",
    "串揚げは中に玉葱と挽肉が入っておりましたが\n",
    "中身はほとんど玉葱のみで、こちらは正直口には合わなかったですね。\n",
    "\n",
    "それでも唐揚げはさすがお肉屋さんの味といった感想でした。\n",
    "\n",
    "ご馳走様でした。\n",
    "\"\"\"\n",
    "tokenizer.encode(text, return_tensors='pt').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
